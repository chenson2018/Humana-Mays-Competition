{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The U.S. Opioid Epidemic\n",
    "\n",
    "According to the 2015 National Survey on Drug Use and Health, 12.5 million people misused prescription opioids. Furthermore:\n",
    "\n",
    "\n",
    "- 2.1 million people misused prescription opioids for the first time\n",
    "- 2 million had prescription opioid misuse disorder\n",
    "- 33,091 died from overdosing on prescription opioids\n",
    "- 15,281 deaths were attributed to overdosing on commonly prescribed opioids\n",
    "- 4 out of 5 people who were addicted to heroin (a cheaper and more affordable street drug) started out using prescription pain pills\n",
    "\n",
    "Once addicted, it is a painfully gruesome process to overcome the symptoms of opioid withdrawal and ultimately conquer the addiction. Early stages of withdrawal are much like the flu. Victims become nauseated, lose their appetite and ability to sleep, and experience aches all throughout their bodies. __That’s just the first week__. In Travis Rieder’s TedTalk, _I was in opioid withdrawal for a month — here's what I learned_ , he describes the month-long withdrawal experience as going through hell. \n",
    "\n",
    "> “I thought I would die. I assumed that I would die… I’m sorry. [pausing to fight back tears] Because if the symptoms didn’t kill me outright, I’d kill myself.”\n",
    "\n",
    "To make matters worse, most doctors simply recommend continuing their prescription use until they can “figure something else out.” Recommendations like this give victims a sensation of despair, imagining what the experience might be like the next time they attempt to wean themselves off of the drug. Will the symptoms amplify? Will this person be addicted to opioids forever?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opioid Addiction Treatment: Digging into the Business Issue\n",
    "\n",
    "When an addict decides to begin rehabilitation, one of the first questions they face is “how am I going to pay for this?” Rehabilitation is expensive and individual requirements vary significantly between patients. According to addictioncenter.com, “for those requiring 60- or 90-day [in-patient rehab] programs, the total average costs could range anywhere from \\\\$12,000 to \\\\$60,000.” \n",
    "\n",
    "For patients who may not need the extensive care of a rehabilitation center, these costs are not negligible. Treatment options such as methadone cost opioid-users around \\\\$4,700 annually. Identifying and mitigating these risks contains the potential to affect both human lives and profit margins.The burden of these costs is carried by health insurance providers and ultimately passed along to customers.\n",
    "\n",
    "# <font color=red>***reference to actionable insights***</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Humana Analytics Competition\n",
    "\n",
    "Using data from a 4-year longitudinal view of events for an MAPD member, participants are required to analyze the data relating to various interactions with Humana. Events such as Rx Claim - Paid, Fully Paid Medical Claim, Inbound Call By Member, New Diagnosis, etc. are included in the dataset. \n",
    "\n",
    "The goal is to develop a predictive model that takes in a set of patient histories up to the point of an \"opioid-naive event\" and assign to each patient a probability of long term opioid therapy being required in the patient's future. These probabilities will be evaluated ROC_AUC paradigm, essentially measuring the ability of the model to correctly classify patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>***Elaborate??????***</font>\n",
    "\n",
    "STILL NEED THESE:\n",
    "\n",
    "Explicit statement of the business issue and a translation into a data problem.\n",
    "Statement and definition of the metrics that will be used to evaluate the abovementioned business problem. \n",
    "\n",
    "40% - Depth and description of analysis resulting in actionable business insights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# featureHealth Analytics’ Analysis\n",
    "<font color=red>***talk about specific tools??????***</font>\n",
    "\n",
    "## Data Preperation\n",
    "\n",
    "As presented in the file HMAHCC_COMP, the data presented several integrity issues that first needed to be addressed. Most prominently, the columns of the provided file mixed several different attributes. To alleviate this issue, we split the data into the following dataframes in Python:\n",
    "\n",
    "- __New_diagnosis__ - all rows that described new diagnoses such as CPD, Hypertension, Top 5, CAD, CHF, and Diabetes\n",
    "- __Call__ - all rows that described calls data\n",
    "- __Non_rx_claim__ - all rows that described claims that were not related to prescription drugs\n",
    "- __New_provider__ - all rows that described a patient seeing a new doctor, physician, or medical practitioner\n",
    "- __Rx_claim__ - all rows that described prescription drug claims\n",
    "- __Rx_paid__ - all rows that described the transactions, so to speak, of prescription drug claims\n",
    "- __Rx_reject__ - all rows that described prescription drugs claims that were later reversed for various reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving the Response Variable\n",
    "\n",
    "We were provided the following definition:\n",
    "\n",
    ">Opioid Naïve will be defined as not having an opioid ‘on hand’ in the preceding 90-day period, based on service date and payday supply count.\n",
    "\n",
    "We designed a function (see below) that first, using the PAY_DAY_SUPPLY_CNT attribute, determined what days each patient had opioids on hand. The function then examined every 180 day period past their first opioid naïve, denoted as day 0 in the dataset. If the patient had any 180 day period with drugs on-hand 162 days or more (90%), we calssified the patient as LTOT. \n",
    "\n",
    "While this is a slight deviation from the exact definition of LTOT, we intentionally used this overapproximation to aid in further seperating the classes and to decrease our model's runtime. Interestingly, we found that implementing this approxamation differed only by approximately 30 individuals out of the 14,000 provided patient histories ($\\sim$.2%), highlighting that the first six months past a qualifying event serve as a key indicator of opioid use.\n",
    "\n",
    "Our derived response variable showed that the classes were nearly equal in distribution, with 50.4% classified as LTOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LTOT(self):\n",
    "\n",
    "    def get_LTOT(ID):\n",
    "        try:\n",
    "            group = self.opioid_data_grouped.get_group(ID)\n",
    "            frame = group[['Days', 'PAY_DAY_SUPPLY_CNT']].drop_duplicates()\n",
    "            frame = frame[frame['Days']>=0]\n",
    "            frame['drugs until'] = (frame['Days'] + frame['PAY_DAY_SUPPLY_CNT']).astype(int)\n",
    "            frame['range'] = frame.apply(lambda x : range(x['Days'].astype(int),x['drugs until'].astype(int)),1)\n",
    "\n",
    "            concat = concatenated = chain(*list(frame['range']))\n",
    "            concat = set(concat)\n",
    "\n",
    "            day_frame = pd.DataFrame(columns = ['Days', 'Has Drug?'])\n",
    "            day_frame['Days'] = range(max(concat)+1)\n",
    "            day_frame['Has Drug?'] = (day_frame['Days'].isin(concat))\n",
    "\n",
    "            for n in range(180,len(day_frame)+1):\n",
    "                frame_slice = day_frame.iloc[n-180:n]\n",
    "                drug_days = np.sum(frame_slice['Has Drug?'])\n",
    "\n",
    "                if drug_days >= 162:\n",
    "                    return (True, n-180, n)\n",
    "\n",
    "            return (False, np.nan, np.nan)\n",
    "        except:\n",
    "            return (np.nan, np.nan, np.nan)\n",
    "\n",
    "    id_list = self.raw_df['id'].drop_duplicates().values\n",
    "\n",
    "    response_variable = pd.DataFrame(id_list, columns = ['id'])\n",
    "    response_variable['LTOT'] = response_variable['id'].map(get_LTOT)\n",
    "\n",
    "    response_variable[['LTOT', 'Begining Date', 'End Date']] = \\\n",
    "    pd.DataFrame(response_variable['LTOT'].tolist(), index = response_variable.index)\n",
    "\n",
    "    self.response_variable = response_variable.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "In the preliminary research stage, we first hypothesized that it would be most effective to engineer features that would identify drug-seeking behavior. However, as we researched the subject further we found that the data did not support this assumption. \n",
    "\n",
    "We analyzed:\n",
    "\n",
    "- how many times a member switched providers \n",
    "- how many times a member called Humana and why\n",
    "- how many diagnoses a member received at once or altogether\n",
    "- how many times a member was denied opioids at each level of strength\n",
    "\n",
    "None of these features seemed to correspond with a member becoming LTOT. We then tried to understand the mechanism of addiction to opioids through outside research. We watched and read a myriad of YouTube videos and online articles to uncover what new potential features we could use in our analysis. Based on this research, we formed a new set of hypotheses:\n",
    "\n",
    "Opioid addiction is primarily connected with\n",
    "\n",
    "- the length of prescriptions of opioids\n",
    "- the strength of the medication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypotheses to inspect\n",
    "\n",
    "#### (a) Length of prescriptions: the longer a patient consumes opioids, the more likely they are to become LTOT.\n",
    "\n",
    "Here we looked at the PAY_DAY_SUPPLY_CNT on day 0, where PAY_DAY_SUPPLY_CNT represents the number of days a patient takes opioid drugs. As shown in the table below, around 93% of patients with a high SUPPLY_CNT_level (over thirty days worth of opioids on-hand) are classified as LTOT.\n",
    "\n",
    "Vice versa, only 18% in low SUPPLY_CNT_level group are classified as LTOT. We therefore concluded that the initial length of prescriptions is an important indicator of LTOT risk.\n",
    "\n",
    "<img src=\"sc2.png\" style=\"width: 300px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Strength of the medication: the stronger drug used, the more likely they are to become LTOT.\n",
    "\n",
    "Take HYDROCODONE-ACETAMINOPHEN as an example, the most commonly used opioid drug in this dataset. Within this opioid, three varieties of drug strength are available, ranging from 5-325 MG to 10-325 MG. \n",
    "\n",
    "As shown in the table below, 70% of patients who were prescribed the strongest type on day 0 became classified as LTOTs, while only 33% of patients who took the lower strength equivalent became classified as LTOT. We concluded that the generic name (including type) of the prescibed medicine could be a significant predictor of LTOT classification. \n",
    "\n",
    "<img src=\"sc1.png\" style=\"width: 500px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Based on the assumptions outlined above, we sought to create a set of features that caputured information that indicated the strength and duration of prescribed opioids. We derived the following:\n",
    "\n",
    "- __SUPPLY_CNT_on_day0:__ opioid supply days at the time of the qualifying event  \n",
    "- __total_SUPPLY_CNT_prior:__ total opioid supply days prior to the qualifying event \n",
    "- __Supply_times:__ total number of instances of opioid perscriptions\n",
    "- __PAYABLE_QTY_on_day0:__ amount of opioids supplied at the time of the qualifying event (amount of physical pills)\n",
    "- __total_PAYABLE_QTY_prior:__ amount of opioids supplied prior to the qualifying event (amount of physical pills)\n",
    "- __MME_on_day0:__ Morphine Milligram Equivalence (MME)\n",
    "- __max_MME_prior:__ maximum MME prior to the qualifying event\n",
    "- __avg_MME_prior:__ average MME prior to the qualifying event\n",
    "- __MME_times_SUPPLY_day_0:__ MME multiplied by opioid supply days at the time of the qualifying event\n",
    "\n",
    "Principal Componets of Generic Attribute - \n",
    "\n",
    "To incorporate the information from the generic name of the opioids perscribed to each patient, we utilized the dimensionality reduction technique of principal components. First for each patient we compiled the PAY_DAY_SUPPLY_CNT of each of the 103 generic names prescribed to each patient on the day of their qualifying event.\n",
    "\n",
    "Applying the principal components alogrithim, we reduced these 103 columns to a set of ten columns for each patient, which was calulated to capture 92.8% of variance within the dataset. \n",
    "\n",
    "Cost terms:\n",
    "\n",
    "These terms describe certain attributes at the time of the qualifying event:\n",
    "\n",
    "- __total_costs_on_day_0__\n",
    "- __total_net_payment_on_day_0__\n",
    "- __net_payment_portion_on_day_0__\n",
    "- __opioid_cost_portion_on_day_0__\n",
    "\n",
    "\n",
    "Interaction terms:\n",
    "\n",
    "These terms certain attributes at the time of the qualifying event, normalized by the supply count at the time of the qualifying even:\n",
    "\n",
    "- __total_cost_divide_SUPPLY_day_0__\n",
    "- __total_net_payment_divide_on_day_0__\n",
    "- __np_portion_divide_SUPPLY_day_0__\n",
    "- __oc_portion_divide_SUPPLY_day_0__\n",
    "- __max_MME_prior_divide_SUPPLY_day_0__\n",
    "- __avg_MME_prior_divide_SUPPLY_day_0__\n",
    "- __tsc_prior_divide_SUPPLY_day_0__\n",
    "- __tpa_prior_divide_SUPPLY_day_0__\n",
    "- __oc_day_0_divide_SUPPLY_day_0__\n",
    "- __np_day_0_divide_SUPPLY_day_0__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Term Interpretation\n",
    "\n",
    "__Features divided by SUPPLY_CNT_on_day0__\n",
    "\n",
    "By visualizing the difference between our validation model predictions and actual data (as shown below), we found that there was a strong connection between the opoid supply count on the day of the qualifying event, albeit with systematic residuals.\n",
    "\n",
    "Through approximately through an inital supply count of 0-20, the variations in LTOT classification are nearly a perfect mirror of the variations of our model predictions, but systematically underpredict the proportion of LTOT. Past this point, at approximately an initial supply count of 30, our model uniformly overpredicts the LTOT rate.\n",
    "\n",
    "Together with the fact SUPPLY_CNT_on_day0 contributes the most in feature importance for several models, we conclude that the models relied too much on this particular feature, potentially being swayed by confounding variables. To reduce the impact of SUPPLY_CNT_on_day0, we divided features by SUPPLY_CNT_on_day0 and created interaction terms, providing an incremental improvements on our ROC AUC scores.\n",
    "\n",
    "<img src=\"cool_graph.png\" style=\"width: 400px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Exploration\n",
    "\n",
    "As we began to explore potential models, we divided the data into three pieces: \n",
    "\n",
    "- training set: consisting of ⅔ of the features derived from HMAHCC_COMP\n",
    "- validation set: consisting of ⅓ of the features derived from HMAHCC_COMP\n",
    "- holdout set: the features derived from HMAHCC_HOLDOUT\n",
    "\n",
    "We would use the training set to test models, the validation set to estimate out-of-sample accuracy and ROC AUC score, and finally only use the holdout set while making our final predictions.  \n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "Because this is a classification problem, we first tested all of our features using simple Logistic Regression. Logistic Regression provided a weak predictor, but the results allowed us to efficiently gain an intuition for testing new features and various hypotheses. \n",
    "\n",
    "While we did not incorporate this into our final solution, it provided a baseline to derive some less obvious information provided by the dataset.\n",
    "\n",
    "## Random Forests\n",
    "\n",
    "Early in our analysis we used a random forest classifier, an ensemble decision tree model that uses cross validation and bootstrapping to simulate a larger dataset. \n",
    "\n",
    "In order to adjust our model's hyperparameters, we used the grid search method to adjust features such as the decision tree's Max_depth and min_samples_leaf to prevent overfitting, while other parameters such as n_estimators and max_features were set at a higher level to increase model complexity. \n",
    "\n",
    "On the validation set, this model provided an ROC AUC score of 0.9132\n",
    "\n",
    "<img src=\"rf.png\" style=\"width: 500px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this model performed well in terms of ROC AUC score, we questioned the distribution of probabilities it predicted:\n",
    "\n",
    "<img src=\"rf_dist.png\" style=\"width: 400px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Tree\n",
    "\n",
    "Next we tried another variation of decision trees, a gradient boosting tree. This model sequentially adds predictors to a decision tree ensemble, each one correcting its predecessor. This method attempts to fit the new predictor (or successor) to the residual errors made by the previous predictor/predecessor. In general, gradient boosting trees generally have shorter training time than random forests as they train much fewer trees.\n",
    "\n",
    "Here we built Gradient Boosting Trees using LightGBM package, design to maximize runtime efficiency. We also applied a grid search to tune hyperparameters: we choose a higher n_estimators to increase complexity, and at the same time we set a lower max_depth at 3 to prevent overfitting. \n",
    "\n",
    "This tuned model achieved an AUC score of 0.9284 on the validation set, which was the best performance across all other models, and again provided the additional benefit of a ranking of variable importance:\n",
    "\n",
    "<img src=\"gb.png\" style=\"width: 500px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, while this model performed well in terms of ROC AUC score, we questioned the distribution of probabilities it predicted, even more dramatic than the previous model:\n",
    "\n",
    "<img src=\"gb_dist.png\" style=\"width: 400px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "Neural Network models are built with layers of neurons. Neurons of a layer are determined by a combination of weights and inputs from the previous layer, as well as the activation function. The process allows Neural Networks to model complex nonlinear relationships between features and response variables. With proper tuning, it generally achieves decent performance. \n",
    "\n",
    "At the tuning stage, we applied early stopping to prevent overfitting. Grid search tuning indicated that we should use 128 neurons on the first hidden layer and 64 neurons on the second hidden layer. However, this Neural Network model underperformed the two other tree-based models on this dataset, with an ROC AUC score of 0.8679.\n",
    "\n",
    "While neural nets do not naturally produce a measure of variable importance, we were able to derive a measure of this by examining the sum of the absolute values of the weights between the input layer and the first hidden layer. While this does not account for the behavior and the additional hidden layers, it does provide some intuition:\n",
    "\n",
    "<img src=\"nn.png\" style=\"width: 500px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we questioned the distribution of probabilities it predicted, which almost appears trimodal (thus difficult for a threshold to seperate classes):\n",
    "\n",
    "<img src=\"nn_dist.png\" style=\"width: 400px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Selection\n",
    "\n",
    "Given these three models, all with relatively adequate ROC AUC scores, we decided to create an ensemble model that averaged the probabilities of any given pair of predicted probabilities, yielding the following scores: \n",
    "\n",
    "Individual Models:\n",
    "- __Gradient Boosting ROC AUC:__ 0.9285\n",
    "- __Random Forest ROC AUC:__ 0.9132\n",
    "- __Neural Net ROC AUC:__ 0.8680 \n",
    "\n",
    "Two Model Averages:\n",
    "- __Gradient Boosting and Random Forest ROC AUC:__ 0.9254\n",
    "- __Gradient Boosting and Neural Net ROC AUC:__ 0.9131\n",
    "- __Random Forest and Neural Net ROC AUC:__ 0.8979 \n",
    "\n",
    "Three Model Average:\n",
    "- __3 Model Average ROC AUC:__ 0.9152\n",
    "\n",
    "\n",
    "While the best overall model solely in terms of predictive power was given by gradient boosting, we choose the combination of gradient boosting and random forest as our final model for the following reason:\n",
    "\n",
    "- the difference in ROC AUC score was nearly negligible (<0.0035)\n",
    "- taking an ensemble of two decision trees gives a large degree of interpretability\n",
    "- using two models with different variable importances increases the ability of the model to handle diverse input\n",
    "- in examing the distribution of predicted probabilities, we found that this ensemble best matched our expectation of LTOT (see figure below)\n",
    "\n",
    "<img src=\"dist.png\" style=\"width: 400px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further gain intuition regarding the performance of our model, we calculated the result of setting different classification thresholds for our model, trying each value between 0 and 1 with a step size of 0.002\n",
    "\n",
    "Given the validation set, this process returned a threshold of 0.586, aligning with our prior knowledge of the LTOT distribution given in our training set. From this process we were also able to construct the ROC curve of our validation set:\n",
    "\n",
    "<img src=\"roc.png\" style=\"width: 400px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally this allowed us to construct a confusion matrix for the validation set:\n",
    "\n",
    "<img src=\"confusion.png\" style=\"width: 275px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Analysis and Actionable Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior to the point of prescribing a patient, we recommend introducing our model into doctors' decision-making process. Taking our model into account we can recommend a reduced dosage that is less likely to induce LTOT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the variable importance (see graphs above), the two most actionable and significant variables are aspects of the initial prescription:\n",
    "\n",
    "- supply count on day zero\n",
    "- MME on day zero\n",
    "\n",
    "Both of our directly actionable items can be controlled by the prescribing doctor. By using our model as a company-wide guideline for what levels of prescription are likely to produce an LTOT patient, we can incentivize doctors to make decisions that reduce the overall amount of LTOT patients. For example, a 27% reduction in supply count on day zero would result in a 10% decrease in LTOT probability, as determined by logistic regression (see chart below). \n",
    "\n",
    "Beyond these two immediately actionable variables, the next most important to consider are:\n",
    "\n",
    "- total payable quantity prior to day zero\n",
    "- total supply count prior to day zero\n",
    "\n",
    "It is important to note that by reducing the impact of our immediately actionable variables, we can then begin to impact the secondary variables of importance in the long term. This is because prior exposure to opioids still plays a significant role in being susceptible to LTOT classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logit.png\" style=\"width: 500px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Graph Interpretation:__ To estimate the affect of decrease in SUPPLY_CNT_on_day0. We ran logistic Regressin model on modified training data where we graduatly decreased the feature SUPPLY_CNY_on_day0. The line in the chart shows how much we can reduce LTOT probability by decreasing SUPPLY_CNT_on_day0, while the red point shows 27% decrease in **SUPPLY_CNT_on_day0 can lead 10% reduction in probability of becoming LTOTs.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the benefits of lowering LTOTs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. External Impact: Improve the quality of patients' and their families' lives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in the beginning of our report, opioid addiction can have a significant negative impact on the quality of one's life. It is not only a brutally agonizing process to overcome the symptoms of withdrawal, but also increases the likelihood that one will end up using heroin. Traumas like these effect the lives of the patient and the family. If avoided altogether, Humana can have a positive impact the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Internal Impact: Brand Image as a Social Reformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the positive impact of reducing LTOT's, Humana can position itself as a leading social reformer in the health insurance space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Internal Impact: Cost Savings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we can decrease the prabability of LTOT's by 10%, we can save $2.8 million of costs on opioid drugs alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To derive this number, we used Humana's portion of the costs of all opioid prescriptions in the dataset to calculate the average costs of opioids per patient per year (see table below). We then used the Humana member rate (as of June 2019), the true population LTOT rate, additional costs from the table below, and the decrease in LTOT probability to calculate these savings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"avg_costs.png\" style=\"width: 500px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2834853.3507840005"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Humana_member = 16600000 # as of June 2019\n",
    "LTOT_rate = 0.0104 # as provided by Humana\n",
    "LTOT_extra_opioid_costs = (190.555065 - 26.349009)\n",
    "decrease_LTOT_probability = 0.1\n",
    "\n",
    "# Opioid costs saving = \n",
    "Humana_member * LTOT_rate * LTOT_extra_opioid_costs * decrease_LTOT_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, for each patient that successfully avoids becoming LTOT, Humana can capitalize on the cost savings in reduced costs of the highly volatile rehabilitation treatments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actionable Steps:\n",
    "1. Start small, work with one hospital, build a program/app that shows the probability of patients becoming LTOTs whenever doctors intend to prescribe opioids.  **add time needed to make one prediction**\n",
    "\n",
    "2. At this point, we can also leverage this effort to gain press exposure and build an image of trying to do good to the society.\n",
    "\n",
    "3. Keep tracking these patients for one year. Test if the number of new LTOTs decreased comparing to historical data.\n",
    "\n",
    "4. Expand to other hospitals.\n",
    "\n",
    "\n",
    "### Risks/ future analysis\n",
    "1. Regulation: need to consult lawyers to determine an illegible way to incorporate the model into a doctor's decision process. While further legal clarification is required,  we believe the risk is limited as our model does not discriminate against personal identities.\n",
    "\n",
    "2. Better model: we can incorporate data after day 0 into the model and further strengthen the prediction power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalable Deliverable: Production Ready Code\n",
    "\n",
    "One of the primary strengths that our code provides is an easily applicable template that allows for the model to automatically be adjusted over time and to take as input any training and test data that has the same attributes given in this competition.\n",
    "\n",
    "In the file \"humana_class.py\" is a Python class object that takes as input a dataframe with the structure given in the provided competition and holdout sets, and gives as its output all of the discussed features, including the derivation of the response variable for a given training set where data after the qualifying event is provided. Because of the portability of using a class object, we can supply our model with new data over time, and account for factors such as geographical differences.\n",
    "\n",
    "Additionally, the model itself is also written as a Python class object, taking as its input the extracted features from a pair of test and training set. It has the capability to produce metrics for variable importance and setting prediction class thresholds, and again is able to handle input that changes over time as well as descibe how these attributes change over time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
