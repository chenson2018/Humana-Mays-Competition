{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv(\"test_features.csv\", index_col = 0)\n",
    "training_features = pd.read_csv(\"training_features.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat_fill = test_features.copy()\n",
    "test_feat_fill = test_feat_fill.replace([np.inf, -np.inf], np.nan)\n",
    "test_feat_fill =test_feat_fill.fillna(test_feat_fill.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, train_set, test_set):\n",
    "        self.train_set = train_set\n",
    "        self.test_set = test_set\n",
    "        \n",
    "        X = train_set.iloc[:,1:]\n",
    "        y = train_set.iloc[:,0].map(lambda x: 1 if x == True else 0 )\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.33, random_state=33)\n",
    "        \n",
    "        \n",
    "    def Random_Forest(self):\n",
    "        rf_model = RandomForestClassifier(n_estimators=300, \n",
    "                                  max_depth=10,\n",
    "                                  random_state=100,\n",
    "                                    max_features=0.5,\n",
    "                                    min_samples_leaf=5)\n",
    "        \n",
    "        cv_results = cross_validate(rf_model, self.X_train, self.y_train, cv=3,\n",
    "                            scoring= 'roc_auc',\n",
    "                            return_train_score=True,\n",
    "                            return_estimator =True)\n",
    "        \n",
    "        rf_model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        importance = pd.Series(rf_model.feature_importances_, index=self.X_train.columns)\n",
    "        self.rf_importance = importance.sort_values()[-15:] # show top 15\n",
    "        \n",
    "        return rf_model.predict_proba(self.test_set)[:,1]\n",
    "    \n",
    "    def LGB(self):\n",
    "        bst = lgb.LGBMClassifier(boosting_type= 'gbdt',\n",
    "                        objective = 'binary',\n",
    "                        max_depth = 3,\n",
    "                        n_estimators = 1000)\n",
    "\n",
    "        bst.fit(self.X_train.values, self.y_train.values)\n",
    "        \n",
    "        importance = pd.Series(bst.feature_importances_, index=self.X_train.columns)\n",
    "        self.GBM_importance = importance.sort_values()[-15:] # show top 15\n",
    "        \n",
    "        return bst.predict_proba(self.test_set)[:,1]\n",
    "    \n",
    "    def Neural_Net(self):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.X)\n",
    "        \n",
    "        X_scale = scaler.transform(self.X)\n",
    "        y_array = self.y.values\n",
    "        \n",
    "        X_train, X_test_s, y_train, y_test = train_test_split(X_scale, y_array, test_size=0.33, random_state=33)\n",
    "        X_train_mlp, X_validation, y_train_mlp, y_validation = train_test_split(X_train, y_train, test_size=0.15, random_state=33)\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "        #First Hidden Layer\n",
    "        model.add(Dense(128, activation='relu', kernel_initializer='random_normal', input_dim=X_train.shape[1]))\n",
    "\n",
    "        #Second  Hidden Layer\n",
    "        model.add(Dense(64, activation='relu', kernel_initializer='random_normal'))    \n",
    "        \n",
    "        #Output Layer\n",
    "        model.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # add early stop to prevent overfitting\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=50)\n",
    "        mc = ModelCheckpoint('best_model2.h5', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_split = 0.15,\n",
    "                            epochs=4000, verbose=0, callbacks=[es, mc])\n",
    "\n",
    "        saved_model = load_model('best_model2.h5')\n",
    "        \n",
    "        #scale test data\n",
    "        scaler.fit(self.test_set)\n",
    "        X_test_scale = scaler.transform(self.test_set)\n",
    "        \n",
    "        NN_predict = saved_model.predict_proba(X_test_scale)\n",
    "        nn_prob = np.array([ x[0] for x in NN_predict])\n",
    "        \n",
    "        self.weights, self.biases = saved_model.layers[0].get_weights()\n",
    "        \n",
    "        return nn_prob\n",
    "    \n",
    "    def predict(self):\n",
    "        rf_predictions = self.Random_Forest()\n",
    "        lgb_predictions = self.LGB()\n",
    "        #nn_predictions = self.Neural_Net()\n",
    "        \n",
    "        self.predictions = pd.DataFrame({'LGB':lgb_predictions,\n",
    "                                         'Random Forest':rf_predictions,\n",
    "                                         #'Neural Net':nn_predictions\n",
    "                                          }, \n",
    "                                          index = self.test_set.index)\n",
    "\n",
    "        #self.predictions['Model Average'] = self.predictions.mean(axis = 1)\n",
    "        self.predictions['RF+LGB'] = (self.predictions['LGB']+self.predictions['Random Forest'])/2\n",
    "        \n",
    "        return self.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validationModel = Model(train_set=training_features, test_set=test_feat_fill)\n",
    "validation_predictions = validationModel.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient1 = test_feat_fill[test_feat_fill.index == 'ID38179240346']\n",
    "patient2 = test_feat_fill[test_feat_fill.index == 'ID14418595663']\n",
    "patient3 = test_feat_fill[test_feat_fill.index == 'ID4467853207']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_inital(patient_features, new_SC_0):\n",
    "    old_SC_0 = patient_features['SUPPLY_CNT_on_day0'].values[0]\n",
    "    \n",
    "    mult_factor = new_SC_0/old_SC_0\n",
    "    divide_factor = old_SC_0/new_SC_0\n",
    "    \n",
    "    mme = patient_features[['MME_on_day0']]\n",
    "    \n",
    "    sc = patient_features[['SUPPLY_CNT_on_day0']]*(mult_factor)\n",
    "    \n",
    "    initials = patient_features[['PAYABLE_QTY_on_day0',\n",
    "       'max_MME_prior', 'avg_MME_prior', 'total_SUPPLY_CNT_prior',\n",
    "       'total_PAYABLE_QTY_prior', 'opioid_cost_on_day_0',\n",
    "       'opioid_net_payment_on_day_0', 'supply_times', 'total_costs_on_day_0',\n",
    "       'total_net_payment_on_day_0', 'net_payment_portion_on_day_0',\n",
    "       'opioid_cost_portion_on_day_0']]\n",
    "    \n",
    "    mme_sc = patient_features[['MME_times_SUPPLY_day_0']]*(mult_factor)\n",
    "    \n",
    "    divide = patient_features[['total_cost_divide_SUPPLY_day_0', 'total_net_payment_divide_on_day_0',\n",
    "       'np_portion_divide_SUPPLY_day_0', 'oc_portion_divide_SUPPLY_day_0',\n",
    "       'max_MME_prior_divide_SUPPLY_day_0',\n",
    "       'avg_MME_prior_divide_SUPPLY_day_0', 'tsc_prior_divide_SUPPLY_day_0',\n",
    "       'tpa_prior_divide_SUPPLY_day_0', 'oc_day_0_divide_SUPPLY_day_0',\n",
    "       'np_day_0_divide_SUPPLY_day_0']]*(divide_factor)\n",
    "    \n",
    "    pcs = patient_features[['generic_pc0', 'generic_pc1',\n",
    "       'generic_pc2', 'generic_pc3', 'generic_pc4', 'generic_pc5',\n",
    "       'generic_pc6', 'generic_pc7', 'generic_pc8', 'generic_pc9']]\n",
    "    \n",
    "    concat = pd.concat([mme, sc, initials, mme_sc, divide, pcs], axis = 1)\n",
    "    \n",
    "    return concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a range for each patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_range(patient_features, sc_low, sc_high, step):\n",
    "    \n",
    "    patient_options = []\n",
    "    \n",
    "    for sc in range(sc_low, sc_high, step):\n",
    "        df = change_inital(patient_features, sc)\n",
    "        patient_options.append(df)\n",
    "        \n",
    "    patient_options = pd.concat(patient_options)\n",
    "    \n",
    "    new_model = Model(train_set=training_features, test_set=pd.concat([test_feat_fill, patient_options]))\n",
    "    new_predictions = new_model.predict()\n",
    "    \n",
    "    return new_predictions.iloc[-len(patient_options):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sc = 1\n",
    "max_sc = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "patient1_range = get_prediction_range(patient1, min_sc, max_sc, 1)\n",
    "patient2_range = get_prediction_range(patient2, min_sc, max_sc, 1)\n",
    "patient3_range = get_prediction_range(patient3, min_sc, max_sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [patient1_range, patient2_range, patient3_range]\n",
    "patients = [patient1, patient2, patient3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_inital_sc = []\n",
    "\n",
    "for patient in patients:\n",
    "    sc = test_features[test_features.index == patient.index[0]]['SUPPLY_CNT_on_day0'][0]\n",
    "    pred = validation_predictions[validation_predictions.index == patient.index[0]]['RF+LGB'].values[0]\n",
    "    \n",
    "    patient_inital_sc.append((sc, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_inital_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Patient 1 (high LTOT)', 'Patient 2 (low LTOT)', 'Patient 3 (threshhold LTOT)']\n",
    "colors = ['red', 'green', 'blue']\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.ylim((0, 1.1))\n",
    "\n",
    "for count, patient in enumerate(ranges):\n",
    "    plt.plot(range(min_sc, max_sc), \n",
    "             patient['RF+LGB'].values, \n",
    "             label = labels[count],\n",
    "             color = colors[count])\n",
    "\n",
    "for inital in patient_inital_sc:\n",
    "    plt.scatter(*inital, color = 'black', s=100, zorder = 3)\n",
    "\n",
    "plt.hlines(y=.586, xmin=min_sc, xmax=max_sc, label = \"LTOT Threshhold\")\n",
    "plt.xlabel('Inital Supply Count')\n",
    "plt.ylabel('LTOT Model Prediction')\n",
    "plt.legend()\n",
    "plt.savefig('full.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5,5))\n",
    "plt.ylim((0, 1.1))\n",
    "\n",
    "plt.plot(range(min_sc, max_sc), \n",
    "     ranges[0]['RF+LGB'].values, \n",
    "     label = labels[0],\n",
    "     color = colors[0])\n",
    "\n",
    "plt.scatter(*patient_inital_sc[0], color = 'black', s=100, zorder = 3)\n",
    "\n",
    "plt.hlines(y=.586, xmin=min_sc, xmax=max_sc, label = \"LTOT Threshhold\")\n",
    "plt.xlabel('Inital Supply Count')\n",
    "plt.ylabel('LTOT Model Prediction')\n",
    "plt.legend()\n",
    "plt.savefig('p1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5,5))\n",
    "plt.ylim((0, 1.1))\n",
    "\n",
    "plt.plot(range(min_sc, max_sc), \n",
    "     ranges[1]['RF+LGB'].values, \n",
    "     label = labels[1],\n",
    "     color = colors[1])\n",
    "\n",
    "plt.scatter(*patient_inital_sc[1], color = 'black', s=100, zorder = 3)\n",
    "\n",
    "plt.hlines(y=.586, xmin=min_sc, xmax=max_sc, label = \"LTOT Threshhold\")\n",
    "plt.xlabel('Inital Supply Count')\n",
    "plt.ylabel('LTOT Model Prediction')\n",
    "plt.legend()\n",
    "plt.savefig('p2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5,5))\n",
    "plt.ylim((0, 1.1))\n",
    "\n",
    "plt.plot(range(min_sc, max_sc), \n",
    "     ranges[2]['RF+LGB'].values, \n",
    "     label = labels[2],\n",
    "     color = colors[2])\n",
    "\n",
    "plt.scatter(*patient_inital_sc[2], color = 'black', s=100, zorder = 3)\n",
    "\n",
    "plt.hlines(y=.586, xmin=min_sc, xmax=max_sc, label = \"LTOT Threshhold\")\n",
    "plt.xlabel('Inital Supply Count')\n",
    "plt.ylabel('LTOT Model Prediction')\n",
    "plt.legend()\n",
    "plt.savefig('p3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MME Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat_fill.MME_on_day0.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat_fill.MME_on_day0.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_inital_mme(patient_features, new_MME_0):\n",
    "    old_MME_0 = patient_features['MME_on_day0'].values[0]\n",
    "    \n",
    "    MME_factor = new_MME_0/old_MME_0\n",
    "    \n",
    "    mme = patient_features[['MME_on_day0']]*MME_factor\n",
    "    \n",
    "    sc = patient_features[['SUPPLY_CNT_on_day0']]\n",
    "    \n",
    "    initials = patient_features[['PAYABLE_QTY_on_day0',\n",
    "       'max_MME_prior', 'avg_MME_prior', 'total_SUPPLY_CNT_prior',\n",
    "       'total_PAYABLE_QTY_prior', 'opioid_cost_on_day_0',\n",
    "       'opioid_net_payment_on_day_0', 'supply_times', 'total_costs_on_day_0',\n",
    "       'total_net_payment_on_day_0', 'net_payment_portion_on_day_0',\n",
    "       'opioid_cost_portion_on_day_0']]\n",
    "    \n",
    "    mme_sc = patient_features[['MME_times_SUPPLY_day_0']]*(MME_factor)\n",
    "    \n",
    "    divide = patient_features[['total_cost_divide_SUPPLY_day_0', 'total_net_payment_divide_on_day_0',\n",
    "       'np_portion_divide_SUPPLY_day_0', 'oc_portion_divide_SUPPLY_day_0',\n",
    "       'max_MME_prior_divide_SUPPLY_day_0',\n",
    "       'avg_MME_prior_divide_SUPPLY_day_0', 'tsc_prior_divide_SUPPLY_day_0',\n",
    "       'tpa_prior_divide_SUPPLY_day_0', 'oc_day_0_divide_SUPPLY_day_0',\n",
    "       'np_day_0_divide_SUPPLY_day_0']]\n",
    "    \n",
    "    pcs = patient_features[['generic_pc0', 'generic_pc1',\n",
    "       'generic_pc2', 'generic_pc3', 'generic_pc4', 'generic_pc5',\n",
    "       'generic_pc6', 'generic_pc7', 'generic_pc8', 'generic_pc9']]\n",
    "    \n",
    "    concat = pd.concat([mme, sc, initials, mme_sc, divide, pcs], axis = 1)\n",
    "    \n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_range_mme(patient_features, mme_low, mme_high, step):\n",
    "    \n",
    "    patient_options = []\n",
    "    \n",
    "    for sc in range(mme_low, mme_high, step):\n",
    "        df = change_inital_mme(patient_features, sc)\n",
    "        patient_options.append(df)\n",
    "        \n",
    "    patient_options = pd.concat(patient_options)\n",
    "    \n",
    "    new_model = Model(train_set=training_features, test_set=pd.concat([test_feat_fill, patient_options]))\n",
    "    new_predictions = new_model.predict()\n",
    "    \n",
    "    return new_predictions.iloc[-len(patient_options):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mme = 1\n",
    "max_mme = 50\n",
    "mme_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "patient1_range_mme = get_prediction_range_mme(patient1, min_mme, max_mme, mme_step)\n",
    "patient2_range_mme = get_prediction_range_mme(patient2, min_mme, max_mme, mme_step)\n",
    "patient3_range_mme = get_prediction_range_mme(patient3, min_mme, max_mme, mme_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mme_ranges = [patient1_range_mme, patient2_range_mme, patient3_range_mme]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_inital_mme = []\n",
    "\n",
    "for patient in patients:\n",
    "    mme = test_features[test_features.index == patient.index[0]]['MME_on_day0'][0]\n",
    "    pred = validation_predictions[validation_predictions.index == patient.index[0]]['RF+LGB'].values[0]\n",
    "    \n",
    "    patient_inital_mme.append((mme, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_inital_mme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Patient 1 (high LTOT)', 'Patient 2 (low LTOT)', 'Patient 3 (threshhold LTOT)']\n",
    "colors = ['red', 'green', 'blue']\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.ylim((0, 1.1))\n",
    "\n",
    "for count, patient in enumerate(mme_ranges):\n",
    "    plt.plot(range(min_mme, max_mme, mme_step), \n",
    "             patient['RF+LGB'].values, \n",
    "             label = labels[count],\n",
    "             color = colors[count])\n",
    "\n",
    "for inital in patient_inital_mme:\n",
    "    plt.scatter(*inital, color = 'black', s=100, zorder = 3)\n",
    "\n",
    "plt.hlines(y=.586, xmin=min_mme, xmax=max_mme, label = \"LTOT Threshhold\")\n",
    "plt.xlabel('Inital MME')\n",
    "plt.ylabel('LTOT Model Prediction')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(.57, .1225))\n",
    "plt.savefig('full_mme.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5,5))\n",
    "plt.ylim((0, 1.1))\n",
    "\n",
    "plt.plot(range(min_mme, max_mme, mme_step), \n",
    "     mme_ranges[0]['RF+LGB'].values, \n",
    "     label = labels[0],\n",
    "     color = colors[0])\n",
    "\n",
    "plt.scatter(*patient_inital_mme[0], color = 'black', s=100, zorder = 3)\n",
    "\n",
    "plt.hlines(y=.586, xmin=min_mme, xmax=max_mme, label = \"LTOT Threshhold\")\n",
    "plt.xlabel('Inital MME')\n",
    "plt.ylabel('LTOT Model Prediction')\n",
    "plt.legend()\n",
    "plt.savefig('p1_mme.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5,5))\n",
    "plt.ylim((0, 1.1))\n",
    "\n",
    "plt.plot(range(min_mme, max_mme, mme_step), \n",
    "     mme_ranges[1]['RF+LGB'].values, \n",
    "     label = labels[1],\n",
    "     color = colors[1])\n",
    "\n",
    "plt.scatter(*patient_inital_mme[1], color = 'black', s=100, zorder = 3)\n",
    "\n",
    "plt.hlines(y=.586, xmin=min_mme, xmax=max_mme, label = \"LTOT Threshhold\")\n",
    "plt.xlabel('Inital MME')\n",
    "plt.ylabel('LTOT Model Prediction')\n",
    "plt.legend()\n",
    "plt.savefig('p2_mme.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5,5))\n",
    "plt.ylim((0, 1.1))\n",
    "\n",
    "plt.plot(range(min_mme, max_mme, mme_step), \n",
    "     mme_ranges[2]['RF+LGB'].values, \n",
    "     label = labels[2],\n",
    "     color = colors[2])\n",
    "\n",
    "plt.scatter(*patient_inital_mme[2], color = 'black', s=100, zorder = 3)\n",
    "\n",
    "plt.hlines(y=.586, xmin=min_mme, xmax=max_mme, label = \"LTOT Threshhold\")\n",
    "plt.xlabel('Inital MME')\n",
    "plt.ylabel('LTOT Model Prediction')\n",
    "plt.legend()\n",
    "plt.savefig('p3_mme.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
