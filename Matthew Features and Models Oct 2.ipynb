{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "#### Results\n",
    "1. Best performed model is NN with roc_auc_score of 0.8965 on Chris's and my features.\n",
    "2. NN model is saved as 'best_model2.h5'.\n",
    "3. My hypothesis on synthetic drugs doesn't work. I can probably try PCA to improve the 65_brands features(?)\n",
    "\n",
    "#### Next step\n",
    "1. Try PCA on features_matthew_65brands and try to run again.\n",
    "2. Further tune NN, RF.\n",
    "3. Try Gradient Boosting.\n",
    "4. Ensemble these models.\n",
    "\n",
    "#### Data and models\n",
    "1. Features: features_matthew_2, pc_diagnosis, features_matthew_65brands(useless)\n",
    "2. Labels: response_variable_v2\n",
    "3. Models: logistic regression, RF, Neural Network, KNN(useless)\n",
    "\n",
    "#### Structure of code\n",
    "1. Process input and output\n",
    "2. Models\n",
    "\n",
    "#### Issue to be discussed\n",
    "1. In hold_out set, there are [16] ppl has no supply_day. How should we treet them?\n",
    "2. In train data, we have 129 problematic ppl: \n",
    "3. 18 of them have no supply_day data when day >= 0\n",
    "4. 34 of them have no supply_day data through out all period\n",
    "5. 68 of them have no supply_day data when day > 0\n",
    "6. 9 of them have no diagnosis data (but have supply_day data)\n",
    "\n",
    "#### Others\n",
    "1. Make sure make probability prediction when calculating roc_auc_score.\n",
    "2. Ref: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process input and outpur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('C:/Users/spong/Desktop/Humana/HMAHCC_COMP.csv')\n",
    "\n",
    "rx_paid = df[df['event_descr']=='RX Claim - Paid']\n",
    "\n",
    "rx_paid = rx_paid.drop(['event_attr2',\n",
    "                        'event_attr7'],\n",
    "                         axis = 1)\n",
    "\n",
    "rx_paid.columns = ['id',\n",
    "                   'event_descr',\n",
    "                   'gpi_drug_class_description',\n",
    "                   'rx_cost',\n",
    "                   'net_paid_amount',\n",
    "                   'brand_name',\n",
    "                   'drug_group_description',\n",
    "                   'generic_name',\n",
    "                   'member_responsible_amount',\n",
    "                   'gpi_drug_group8_id',\n",
    "                   'Days',\n",
    "                   'PAY_DAY_SUPPLY_CNT',\n",
    "                   'PAYABLE_QTY',\n",
    "                   'MME',\n",
    "                   'DRUG_TYPE',\n",
    "                   'Specialty',\n",
    "                   'Specialty2',\n",
    "                   'Specialty3']\n",
    "\n",
    "opioid_col = ['id',\n",
    "              'gpi_drug_class_description',\n",
    "              'brand_name',\n",
    "              'drug_group_description',\n",
    "              'generic_name',\n",
    "              'gpi_drug_group8_id',\n",
    "              'PAY_DAY_SUPPLY_CNT',\n",
    "              'PAYABLE_QTY',\n",
    "              'MME',\n",
    "              'Specialty',\n",
    "              'Specialty2',\n",
    "              'Specialty3',\n",
    "              'Days']\n",
    "\n",
    "opioid = rx_paid[(rx_paid['PAY_DAY_SUPPLY_CNT'].notnull())&(rx_paid['Days']<=0)][opioid_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### features_matthew_v2\n",
    "supply_day, payable_qty, MME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MME_on_day0</th>\n",
       "      <th>SUPPLY_CNT_on_day0</th>\n",
       "      <th>PAYABLE_QTY_on_day0</th>\n",
       "      <th>max_MME_prior</th>\n",
       "      <th>avg_MME_prior</th>\n",
       "      <th>total_SUPPLY_CNT_prior</th>\n",
       "      <th>total_PAYABLE_QTY_prior</th>\n",
       "      <th>supply_times</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID10010854159</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID10013863216</th>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID10024447278</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1002482139</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>37.254464</td>\n",
       "      <td>789.0</td>\n",
       "      <td>2895.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1003386406</th>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MME_on_day0  SUPPLY_CNT_on_day0  PAYABLE_QTY_on_day0  max_MME_prior  avg_MME_prior  total_SUPPLY_CNT_prior  total_PAYABLE_QTY_prior  supply_times\n",
       "key_0                                                                                                                                                           \n",
       "ID10010854159         15.0                 5.0                 15.0            0.0       0.000000                     0.0                      0.0             1\n",
       "ID10013863216         10.0                90.0                180.0            0.0       0.000000                     0.0                      0.0             1\n",
       "ID10024447278         50.0                 3.0                 20.0           22.5      20.000000                    15.0                     40.0             4\n",
       "ID1002482139          60.0                30.0                120.0           90.0      37.254464                   789.0                   2895.0            29\n",
       "ID1003386406          20.0                15.0                 60.0           50.0      50.000000                     3.0                     20.0             2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features3 = pd.read_csv('features_matthew_v2.csv')\n",
    "features3 = features3.set_index('key_0')\n",
    "features_matthew_v2 = features3.copy()\n",
    "features_matthew_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################################\n",
    "# # code to generate features_matthew_v2\n",
    "# ######################################\n",
    "\n",
    "# opioid_grouped = opioid.groupby(by=['id'])\n",
    "# idtestlist = opioid['id'].drop_duplicates()\n",
    "\n",
    "# features3 = pd.DataFrame()\n",
    "# for ID in idtestlist:\n",
    "#     tmp = opioid_grouped.get_group(ID)\n",
    "\n",
    "#     # MME (per day) on day 0\n",
    "#     # Suuply_CNT on day 0\n",
    "#     on_day0 = tmp[tmp['Days'] == 0] \n",
    "#     if not on_day0.empty:\n",
    "#         MME0 = on_day0['MME'].values[0]\n",
    "#         SC0 = on_day0['PAY_DAY_SUPPLY_CNT'].values[0]\n",
    "#         PQ0 = on_day0['PAYABLE_QTY'].values[0]\n",
    "#     else:\n",
    "#         MME0 = 0\n",
    "#         SC0 = 0\n",
    "#         PQ0 = 0\n",
    "\n",
    "#     # max MME (per day) prior to day 0\n",
    "#     # average MME (per day) prior to day 0\n",
    "#     # Total Supply_CNT prior to day 0\n",
    "#     prior_day0 = tmp[tmp['Days'] < 0]\n",
    "#     if not prior_day0.empty:\n",
    "#         maxMME = np.nanmax(prior_day0['MME'].values)\n",
    "#         avgMME = np.nanmean(prior_day0['MME'].values)\n",
    "#         totalSC = np.sum(prior_day0['PAY_DAY_SUPPLY_CNT'].values)\n",
    "#         totalPQ = np.sum(prior_day0['PAYABLE_QTY'].values)\n",
    "#     else:\n",
    "#         maxMME = 0\n",
    "#         avgMME = 0\n",
    "#         totalSC = 0\n",
    "#         totalPQ = 0\n",
    "\n",
    "#     output = pd.DataFrame({'MME_on_day0': MME0, \n",
    "#                          'SUPPLY_CNT_on_day0': SC0,\n",
    "#                            'PAYABLE_QTY_on_day0': PQ0,\n",
    "#                          'max_MME_prior': maxMME,\n",
    "#                          'avg_MME_prior': avgMME,\n",
    "#                          'total_SUPPLY_CNT_prior': totalSC,\n",
    "#                           'total_PAYABLE_QTY_prior': totalPQ},\n",
    "#                           index = [ID])\n",
    "\n",
    "#     features3 = features3.append(output, sort=False)\n",
    "\n",
    "# # MME_on_day0, max_MME_prior, avg_MME_prior has some missing value, fill with medians\n",
    "# features3['MME_on_day0'] = features3['MME_on_day0'].fillna(np.nanmedian(features3['MME_on_day0']))\n",
    "# features3['max_MME_prior'] = features3['max_MME_prior'].fillna(np.nanmedian(features3['max_MME_prior']))\n",
    "# features3['avg_MME_prior'] = features3['avg_MME_prior'].fillna(np.nanmedian(features3['avg_MME_prior']))\n",
    "\n",
    "# # add one more feature: supply_times\n",
    "# supply_times = opioid.groupby(by=['id'])['PAY_DAY_SUPPLY_CNT'].count()\n",
    "# supply_times = pd.DataFrame(supply_times)\n",
    "# supply_times.columns = ['supply_times']\n",
    "# features3 = features3.merge(supply_times, left_on=features3.index.values, right_on=supply_times.index.values)\n",
    "# features3.to_csv('features_matthew_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### features_matthew_65brands \n",
    "Entries are PAY_DAY_SUPPLY_CNT mean\n",
    "\n",
    "This is not working, probably I can try PCA on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAMADOL HCL</th>\n",
       "      <th>OXYCODONE/ACETAMINOPHEN</th>\n",
       "      <th>HYDROCODONE/ACETAMINOPHEN</th>\n",
       "      <th>OXYCODONE HCL</th>\n",
       "      <th>ACETAMINOPHEN/CODEINE</th>\n",
       "      <th>HYDROMORPHONE HCL</th>\n",
       "      <th>MORPHINE SULFATE ER</th>\n",
       "      <th>ACETAMINOPHEN/CODEINE PHO</th>\n",
       "      <th>ACETAMINOPHEN/CODEINE #3</th>\n",
       "      <th>FENTANYL</th>\n",
       "      <th>...</th>\n",
       "      <th>MEPERITAB</th>\n",
       "      <th>HYDROMORPHONE HCL ER</th>\n",
       "      <th>AVINZA</th>\n",
       "      <th>PERCOCET</th>\n",
       "      <th>NUCYNTA ER</th>\n",
       "      <th>EXALGO</th>\n",
       "      <th>VICOPROFEN</th>\n",
       "      <th>TREZIX</th>\n",
       "      <th>LORCET HD</th>\n",
       "      <th>LEVORPHANOL TARTRATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID10010854159</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID10013863216</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID10024447278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1002482139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.178571</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1003386406</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRAMADOL HCL  OXYCODONE/ACETAMINOPHEN  HYDROCODONE/ACETAMINOPHEN  OXYCODONE HCL  ACETAMINOPHEN/CODEINE  HYDROMORPHONE HCL  MORPHINE SULFATE ER  ACETAMINOPHEN/CODEINE PHO  ACETAMINOPHEN/CODEINE #3  FENTANYL  ...  MEPERITAB  HYDROMORPHONE HCL ER  AVINZA  PERCOCET  NUCYNTA ER  EXALGO  VICOPROFEN  TREZIX  LORCET HD  LEVORPHANOL TARTRATE\n",
       "Unnamed: 0                                                                                                                                                                                                                    ...                                                                                                                            \n",
       "ID10010854159           5.0                      0.0                   0.000000            0.0                    0.0                0.0                  0.0                        0.0                       0.0       0.0  ...        0.0                   0.0     0.0       0.0         0.0     0.0         0.0     0.0        0.0                   0.0\n",
       "ID10013863216          90.0                      0.0                   0.000000            0.0                    0.0                0.0                  0.0                        0.0                       0.0       0.0  ...        0.0                   0.0     0.0       0.0         0.0     0.0         0.0     0.0        0.0                   0.0\n",
       "ID10024447278           0.0                      4.5                   0.000000            0.0                    0.0                0.0                  0.0                        0.0                       0.0       0.0  ...        0.0                   0.0     0.0       0.0         0.0     0.0         0.0     0.0        0.0                   0.0\n",
       "ID1002482139            0.0                      0.0                  28.178571           30.0                    0.0                0.0                  0.0                        0.0                       0.0       0.0  ...        0.0                   0.0     0.0       0.0         0.0     0.0         0.0     0.0        0.0                   0.0\n",
       "ID1003386406           15.0                      0.0                   3.000000            0.0                    0.0                0.0                  0.0                        0.0                       0.0       0.0  ...        0.0                   0.0     0.0       0.0         0.0     0.0         0.0     0.0        0.0                   0.0\n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = pd.read_csv('features_matthew_65brands.csv')\n",
    "# features = features.set_index(['Unnamed: 0'])\n",
    "\n",
    "# features_matthew_65brands = features.copy()\n",
    "# features_matthew_65brands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "## code to generate features_matthew_65brands\n",
    "#############################################\n",
    "\n",
    "# opioid2_grouped = opioid.groupby(by=['id'])\n",
    "\n",
    "# idtestlist = opioid['id'].drop_duplicates()\n",
    "\n",
    "# ## those commented-out codes are used to get other entry values\n",
    "# # def product_sum(df):\n",
    "# #     return(df['MME'].values.dot(df['PAY_DAY_SUPPLY_CNT']e.values))\n",
    "\n",
    "# features = pd.DataFrame()\n",
    "# for ID in idtestlist:\n",
    "#     tmp = opioid2_grouped.get_group(ID)\n",
    "#     output = pd.DataFrame(tmp.groupby(by='brand_name')['PAY_DAY_SUPPLY_CNT'].mean()).T\n",
    "# #     output = output.iloc[0:1,:]\n",
    "#     output.index = [ID]\n",
    "#     # features = pd.concat([output, features], axis=1, sort=False)\n",
    "#     features = features.append(output, sort=False)\n",
    "\n",
    "# features = features.fillna(0)\n",
    "# features.to_csv('features_matthew_65brands.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pc_diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC 1</th>\n",
       "      <th>PC 2</th>\n",
       "      <th>PC 3</th>\n",
       "      <th>PC 4</th>\n",
       "      <th>PC 5</th>\n",
       "      <th>PC 6</th>\n",
       "      <th>PC 7</th>\n",
       "      <th>PC 8</th>\n",
       "      <th>PC 9</th>\n",
       "      <th>PC 10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID10010854159</th>\n",
       "      <td>0.008840</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-0.002999</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID10013863216</th>\n",
       "      <td>0.004783</td>\n",
       "      <td>-0.004110</td>\n",
       "      <td>0.009211</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.001218</td>\n",
       "      <td>-0.004039</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>-0.007012</td>\n",
       "      <td>0.007118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID10024447278</th>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>-0.002873</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.002040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1002482139</th>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.004210</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>-0.003246</td>\n",
       "      <td>-0.001197</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>-0.001723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1003386406</th>\n",
       "      <td>0.001259</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>-0.003560</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>-0.003400</td>\n",
       "      <td>-0.002201</td>\n",
       "      <td>-0.008570</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.004095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   PC 1      PC 2      PC 3      PC 4      PC 5      PC 6      PC 7      PC 8      PC 9     PC 10\n",
       "id                                                                                                               \n",
       "ID10010854159  0.008840  0.006021  0.001393  0.003137 -0.000543 -0.000012 -0.002715  0.000189 -0.002999  0.000369\n",
       "ID10013863216  0.004783 -0.004110  0.009211  0.006220 -0.000302 -0.001218 -0.004039  0.003508 -0.007012  0.007118\n",
       "ID10024447278  0.007123  0.018349 -0.002873  0.001940 -0.000999  0.001292  0.000691 -0.000391 -0.000094 -0.002040\n",
       "ID1002482139  -0.003584 -0.004210  0.000235 -0.003246 -0.001197  0.002330  0.000364 -0.001483  0.000771 -0.001723\n",
       "ID1003386406   0.001259 -0.000543 -0.000644 -0.003560 -0.000509 -0.003400 -0.002201 -0.008570  0.005852  0.004095"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_diagnosis = pd.read_csv('pc_diagnosis.csv')\n",
    "pc_diagnosis = pc_diagnosis.set_index('id')\n",
    "pc_diagnosis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive</th>\n",
       "      <th>LTOT_v2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID10010854159</th>\n",
       "      <td>[0, 706]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID10013863216</th>\n",
       "      <td>[0]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID10024447278</th>\n",
       "      <td>[0]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1002482139</th>\n",
       "      <td>[0]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1003386406</th>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  naive LTOT_v2\n",
       "id                             \n",
       "ID10010854159  [0, 706]   False\n",
       "ID10013863216       [0]    True\n",
       "ID10024447278       [0]    True\n",
       "ID1002482139        [0]    True\n",
       "ID1003386406        [0]   False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_variable = pd.read_csv('response_variable_v2.csv')\n",
    "response_variable = response_variable.dropna()\n",
    "response_variable = response_variable.set_index('id')\n",
    "response_variable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all features and response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LTOT_v2</th>\n",
       "      <th>MME_on_day0</th>\n",
       "      <th>SUPPLY_CNT_on_day0</th>\n",
       "      <th>PAYABLE_QTY_on_day0</th>\n",
       "      <th>max_MME_prior</th>\n",
       "      <th>avg_MME_prior</th>\n",
       "      <th>total_SUPPLY_CNT_prior</th>\n",
       "      <th>total_PAYABLE_QTY_prior</th>\n",
       "      <th>supply_times</th>\n",
       "      <th>PC 1</th>\n",
       "      <th>PC 2</th>\n",
       "      <th>PC 3</th>\n",
       "      <th>PC 4</th>\n",
       "      <th>PC 5</th>\n",
       "      <th>PC 6</th>\n",
       "      <th>PC 7</th>\n",
       "      <th>PC 8</th>\n",
       "      <th>PC 9</th>\n",
       "      <th>PC 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID10010854159</th>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-0.002999</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID10013863216</th>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>-0.004110</td>\n",
       "      <td>0.009211</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.001218</td>\n",
       "      <td>-0.004039</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>-0.007012</td>\n",
       "      <td>0.007118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID10024447278</th>\n",
       "      <td>True</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>-0.002873</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.002040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1002482139</th>\n",
       "      <td>True</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>37.254464</td>\n",
       "      <td>789.0</td>\n",
       "      <td>2895.0</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.004210</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>-0.003246</td>\n",
       "      <td>-0.001197</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>-0.001723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1003386406</th>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>-0.003560</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>-0.003400</td>\n",
       "      <td>-0.002201</td>\n",
       "      <td>-0.008570</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.004095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LTOT_v2  MME_on_day0  SUPPLY_CNT_on_day0  PAYABLE_QTY_on_day0  max_MME_prior  avg_MME_prior  total_SUPPLY_CNT_prior  total_PAYABLE_QTY_prior  supply_times      PC 1      PC 2      PC 3      PC 4      PC 5      PC 6      PC 7      PC 8      PC 9     PC 10\n",
       "ID10010854159   False         15.0                 5.0                 15.0            0.0       0.000000                     0.0                      0.0             1  0.008840  0.006021  0.001393  0.003137 -0.000543 -0.000012 -0.002715  0.000189 -0.002999  0.000369\n",
       "ID10013863216    True         10.0                90.0                180.0            0.0       0.000000                     0.0                      0.0             1  0.004783 -0.004110  0.009211  0.006220 -0.000302 -0.001218 -0.004039  0.003508 -0.007012  0.007118\n",
       "ID10024447278    True         50.0                 3.0                 20.0           22.5      20.000000                    15.0                     40.0             4  0.007123  0.018349 -0.002873  0.001940 -0.000999  0.001292  0.000691 -0.000391 -0.000094 -0.002040\n",
       "ID1002482139     True         60.0                30.0                120.0           90.0      37.254464                   789.0                   2895.0            29 -0.003584 -0.004210  0.000235 -0.003246 -0.001197  0.002330  0.000364 -0.001483  0.000771 -0.001723\n",
       "ID1003386406    False         20.0                15.0                 60.0           50.0      50.000000                     3.0                     20.0             2  0.001259 -0.000543 -0.000644 -0.003560 -0.000509 -0.003400 -0.002201 -0.008570  0.005852  0.004095"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([response_variable[['LTOT_v2']], features_matthew_v2, pc_diagnosis], \n",
    "                axis=1, join='inner')\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5047220820416697"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base line\n",
    "df2['LTOT_v2'].value_counts()[False]/sum(df2['LTOT_v2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.iloc[:,1:]\n",
    "y = df2.iloc[:,0].map(lambda x: 1 if x == True else 0 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue to be discussed: 16 ppl in holdout data has no supply_day values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5984"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_hould_out = pd.read_csv('C:/Users/spong/Desktop/Humana/HMAHCC_HOLDOUT.csv')\n",
    "# opioid_hold_out = df_hould_out[df_hould_out['PAY_DAY_SUPPLY_CNT'].notnull()]\n",
    "# len(opioid_hold_out['ID'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spong\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\spong\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\spong\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\spong\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train roc_auc:  0.8607554404440675\n",
      "test roc_auc:  0.8680379846492545\n",
      "Wall time: 261 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logit_model = LogisticRegression()\n",
    "\n",
    "cv_results = cross_validate(logit_model, X_train, y_train, cv=3,\n",
    "                            scoring= 'roc_auc',\n",
    "                            return_train_score=True)\n",
    "\n",
    "print('train roc_auc: ', np.mean(cv_results['test_score']))\n",
    "\n",
    "logit_model.fit(X_train, y_train)\n",
    "prediction_on_X_test = logit_model.predict_proba(X_test)\n",
    "print('test roc_auc: ', roc_auc_score(y_test, prediction_on_X_test[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF tuned on max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 300}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'max_depth': list(range(1,31,1)),\n",
    "             'n_estimators': [100, 300]}\n",
    "rf = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(rf, parameters, scoring='roc_auc', cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train roc_auc:  0.883797294400928\n",
      "test roc_auc:  0.8929639077123037\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = RandomForestClassifier(n_estimators=rf_grid.best_params_['n_estimators'], \n",
    "                                  max_depth=rf_grid.best_params_['max_depth'],\n",
    "                                  random_state=100)\n",
    "\n",
    "cv_results = cross_validate(rf_model, X_train, y_train, cv=3,\n",
    "                            scoring= 'roc_auc',\n",
    "                            return_train_score=True,\n",
    "                            return_estimator =True)\n",
    "\n",
    "print('train roc_auc: ', np.mean(cv_results['test_score']))\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "prediction_on_X_test = rf_model.predict_proba(X_test)\n",
    "print('test roc_auc: ', roc_auc_score(y_test, prediction_on_X_test[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters we can use to tune RF\n",
    "# parameters = {'n_estimators':list(range(100,2100,100)),\n",
    "#               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#               'min_samples_split': [2, 5, 10],\n",
    "#               'min_samples_leaf': [1, 2, 4],\n",
    "#               'max_features': ['auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score for estimator 0:\n",
      "===================================\n",
      "                         importance\n",
      "SUPPLY_CNT_on_day0         0.249045\n",
      "PAYABLE_QTY_on_day0        0.129916\n",
      "total_SUPPLY_CNT_prior     0.102767\n",
      "total_PAYABLE_QTY_prior    0.093780\n",
      "supply_times               0.055516\n",
      "PC 5                       0.048653\n",
      "PC 6                       0.044982\n",
      "MME_on_day0                0.034482\n",
      "avg_MME_prior              0.031437\n",
      "PC 3                       0.026181\n",
      "PC 7                       0.025797\n",
      "max_MME_prior              0.024172\n",
      "PC 4                       0.024128\n",
      "PC 10                      0.023245\n",
      "PC 9                       0.022927\n",
      "PC 8                       0.022111\n",
      "PC 2                       0.021673\n",
      "PC 1                       0.019190\n",
      "Features sorted by their score for estimator 1:\n",
      "===================================\n",
      "                         importance\n",
      "SUPPLY_CNT_on_day0         0.264216\n",
      "PAYABLE_QTY_on_day0        0.116777\n",
      "total_SUPPLY_CNT_prior     0.108109\n",
      "total_PAYABLE_QTY_prior    0.090165\n",
      "supply_times               0.055570\n",
      "PC 5                       0.046503\n",
      "PC 6                       0.039800\n",
      "avg_MME_prior              0.031902\n",
      "MME_on_day0                0.031742\n",
      "max_MME_prior              0.025804\n",
      "PC 3                       0.025190\n",
      "PC 4                       0.024933\n",
      "PC 9                       0.024814\n",
      "PC 7                       0.024716\n",
      "PC 8                       0.023755\n",
      "PC 10                      0.023616\n",
      "PC 2                       0.021934\n",
      "PC 1                       0.020454\n",
      "Features sorted by their score for estimator 2:\n",
      "===================================\n",
      "                         importance\n",
      "SUPPLY_CNT_on_day0         0.248178\n",
      "PAYABLE_QTY_on_day0        0.133192\n",
      "total_SUPPLY_CNT_prior     0.103459\n",
      "total_PAYABLE_QTY_prior    0.079144\n",
      "PC 5                       0.057036\n",
      "PC 6                       0.048000\n",
      "supply_times               0.047342\n",
      "MME_on_day0                0.036034\n",
      "avg_MME_prior              0.029570\n",
      "PC 3                       0.028559\n",
      "PC 7                       0.026808\n",
      "PC 9                       0.025202\n",
      "PC 10                      0.024995\n",
      "PC 4                       0.024606\n",
      "PC 8                       0.022634\n",
      "max_MME_prior              0.021902\n",
      "PC 2                       0.021732\n",
      "PC 1                       0.021608\n"
     ]
    }
   ],
   "source": [
    "for idx,estimator in enumerate(cv_results['estimator']):\n",
    "    print(\"Features sorted by their score for estimator {}:\".format(idx))\n",
    "    feature_importances = pd.DataFrame(estimator.feature_importances_,\n",
    "                                       index = X.columns,\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print('===================================')\n",
    "    print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to visualize the effect of different hyperparameters of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "# grid = list(range(1,31,1))\n",
    "# train_accuracy = list()\n",
    "# test_accuracy = list()\n",
    "# for i in grid:\n",
    "#     rf_model = RandomForestClassifier(n_estimators=100, max_depth=i,\n",
    "#                                       random_state=0)\n",
    "#     cv_results = cross_validate(rf_model, X_train, y_train, cv=3,\n",
    "#                             scoring= 'accuracy',\n",
    "#                             return_train_score=True)\n",
    "\n",
    "#     train_accuracy.append(np.mean(cv_results['train_score']))\n",
    "#     test_accuracy.append(np.mean(cv_results['test_score']))\n",
    "\n",
    "# test_res = pd.DataFrame([train_accuracy, test_accuracy], index = ['train_accuracy', 'test_accuracy']).T\n",
    "# test_res.set_index = grid\n",
    "# test_res.plot()\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('max_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classifier on tuned K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spong\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 25}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# parameters = {'n_neighbors': list(range(5,205,10))}\n",
    "# neigh = KNeighborsClassifier()\n",
    "# neigh_grid = GridSearchCV(neigh, parameters, scoring='roc_auc', cv=5)\n",
    "# neigh_grid.fit(X_train, y_train)\n",
    "\n",
    "# neigh_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test roc_auc:  0.8159436471332583\n",
      "Wall time: 8.43 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# neigh = KNeighborsClassifier(n_neighbors=25)\n",
    "\n",
    "# cv_results = cross_validate(neigh, X_train, y_train, cv=3,\n",
    "#                             scoring= 'roc_auc',\n",
    "#                             return_train_score=True,\n",
    "#                            return_estimator =True)\n",
    "\n",
    "# print('train roc_auc: ', np.mean(cv_results['test_score']))\n",
    "\n",
    "# neigh.fit(X_train, y_train)\n",
    "# prediction_on_x_test = neigh.predict(X_test)\n",
    "# print('test roc_auc: ', roc_auc_score(y_test, prediction_on_x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scale = scaler.transform(X)\n",
    "y_array = y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y_array, test_size=0.33, random_state=33)\n",
    "X_train_mlp, X_validation, y_train_mlp, y_validation = train_test_split(X_train, y_train, test_size=0.15, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42823, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42823 to 0.42290, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42290 to 0.41398, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.41398\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41398 to 0.41362, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.41362 to 0.41234, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41234 to 0.40958, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.40958\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40958 to 0.40749, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.40749 to 0.40671, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.40671 to 0.40517, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.40517 to 0.40494, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.40494\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.40494\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.40494\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.40494\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.40494\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.40494\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.40494 to 0.40434, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.40434 to 0.40328, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.40328\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.40328 to 0.40228, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.40228\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.40228\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.40228\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.40228\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.40228\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.40228\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.40228\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.40228 to 0.40068, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.40068 to 0.39938, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.39938 to 0.39828, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.39828\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.39828 to 0.39828, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.39828 to 0.39749, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.39749\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.39749\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.39749\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.39749 to 0.39740, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.39740 to 0.39523, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.39523\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.39523\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.39523 to 0.39512, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.39512\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.39512\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.39512 to 0.39408, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.39408\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.39408\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.39408\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.39408 to 0.39396, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.39396 to 0.39252, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.39252 to 0.39231, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.39231\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.39231\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.39231\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.39231\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.39231\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.39231\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.39231\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.39231 to 0.39061, saving model to best_model2.h5\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.39061\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.39061\n",
      "Epoch 00110: early stopping\n",
      "Train: 0.816, Test: 0.829\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "\n",
    "#First Hidden Layer\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='random_normal', input_dim=X_train.shape[1]))\n",
    "\n",
    "#Second  Hidden Layer\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='random_normal'))\n",
    "\n",
    "#Output Layer\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# there's no easy way to incorporate roc_auc in MLP's training process\n",
    "# so I use accuracy, which can be a proxy of roc_auc, to train models\n",
    "# then use roc_auc to assess the prediction on test set\n",
    "\n",
    "# add early stop to prevent overfitting\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "mc = ModelCheckpoint('best_model2.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split = 0.15,\n",
    "                    epochs=4000, verbose=0, callbacks=[es, mc])\n",
    "\n",
    "saved_model = load_model('best_model2.h5')\n",
    "\n",
    "_, train_acc = saved_model.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc on train:  0.8965876529139651\n",
      "roc_auc on test:  0.8965608261117267\n"
     ]
    }
   ],
   "source": [
    "prediction_on_X_train = saved_model.predict_proba(X_train)\n",
    "prediction_on_X_train = [x[0] for x in prediction_on_X_train]\n",
    "print('roc_auc on train: ', roc_auc_score(y_train, prediction_on_X_train))\n",
    "\n",
    "prediction_on_X_test = model.predict_proba(X_test)\n",
    "prediction_on_X_test = [x[0] for x in prediction_on_X_test]\n",
    "print('roc_auc on test: ', roc_auc_score(y_test, prediction_on_X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = lgb.Dataset(X_train.values, y_train.values,\n",
    "#                          feature_name = list(X.columns))\n",
    "\n",
    "# param = {'num_leaves': 31, 'objective': 'binary'}\n",
    "# param['metric'] = 'auc'\n",
    "\n",
    "# num_round = 1000\n",
    "# bst = lgb.train(param, train_data, num_round)\n",
    "\n",
    "# y_test_predict = pd.Series(bst.predict(X_test)).map(lambda x: 1 if x >0.5 else 0)\n",
    "# accuracy_score(y_test, y_test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
